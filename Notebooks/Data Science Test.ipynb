{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iG3t9lsrbw5i"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740551103369,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "KJ3tGaAjpquY"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Sharing Vision/AppData/Local/Programs/Python/Python312/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score,roc_auc_score\n",
    "import joblib  # To save the model\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24876,
     "status": "ok",
     "timestamp": 1740547853665,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "E4hGKHN5btAc",
    "outputId": "c9b3baf0-fe0c-438a-a696-63e4f728ae5c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1740547857676,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "hXpfOii3b0KD",
    "outputId": "ee427b96-c4e2-4060-e6ed-b796eb74405a"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/My Drive/Test OCBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_V_fY6gcJfd"
   },
   "source": [
    "The first stage is to import several libraries and read the data. You can upload data directly to Google Colab or mount it to your drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "executionInfo": {
     "elapsed": 4410,
     "status": "ok",
     "timestamp": 1740551706319,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "l2uUQ-jccLAf",
    "outputId": "3af606ae-888f-4688-c8bd-e86bbb138630"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "cleaned_data = []\n",
    "with open(\"dataset.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        line = re.sub(r'^\"|\"$', '', line)\n",
    "        line = re.sub(r'\"\"', '\"', line)\n",
    "        cleaned_data.append(line)\n",
    "\n",
    "cleaned_file_path = \"cleaned_dataset.csv\"\n",
    "with open(cleaned_file_path, \"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    file.write(\"\\n\".join(cleaned_data))\n",
    "\n",
    "df_final = pd.read_csv(cleaned_file_path, delimiter=\",\", engine=\"python\")\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB3NSPppmSQp"
   },
   "source": [
    "Need to preprocess the file because of improper quotation marks inside the CSV file and the CSV also has inconsistent delimiters or extra embedded commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1740547988790,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "TsmkSIVSmy7z",
    "outputId": "4b82ae50-b2b4-436e-ca8f-c9b7d9ed3fd1"
   },
   "outputs": [],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2LASFPfnO-2"
   },
   "source": [
    "The dataset tconsists of 41,022 entries with 21 columns. There are 6 columns with missing values, which are: ph_call_log_stats,ph_country_code, fb_gender, fb_dob, fb_last_updated_date, fb_relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QBR9Cx1oSXc"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1740547991485,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "dfQc4I9XoT2m"
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['flag_bad','de_gender','de_employment_type','de_education','de_marital_status','ph_other_device_info','ph_call_log_stats',\n",
    "                       'ph_country_code','ph_app_list','fb_gender','fb_dob','fb_relation','de_accomodation_type']\n",
    "numerical_columns = list(set(df_final.columns) - set(categorical_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDzXjRhqWn_D"
   },
   "source": [
    "### EDA Catgeorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1740468929728,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "hxRvh3QEWse4",
    "outputId": "4e9f6ffa-bb0d-4be5-9f36-2bc1a3450d06"
   },
   "outputs": [],
   "source": [
    "for column in categorical_columns:\n",
    "  print(column)\n",
    "  display(df_final[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12t654KIwWrT"
   },
   "source": [
    "#### Count Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1740457946281,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "htF2dB70Xx_O",
    "outputId": "f4416e1b-28bf-4c3c-d307-1d9e1b4e12d8"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='flag_bad', data=df_final)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyKuC7M5awuh"
   },
   "source": [
    "* Good Users **Outnumber** Bad Users: There are **significantly more** good users (35,702) (87%) compared to bad users (5,320) (13%).\n",
    "\n",
    "* **Ratio** of Good to Bad Users: This means that for every bad user, there are approximately **6.7 good users**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1740461613862,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "vfyzvALpmAfx",
    "outputId": "cb4e532e-dc5e-4e12-caee-9c8d791914a4"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='de_gender', data=df_final)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjkromnemdVc"
   },
   "source": [
    "* Higher Male Count: The bar chart indicates that the count of males (25,086) is **higher than** the count of females (15,936).\n",
    "\n",
    "* Distribution of Gender:\n",
    "\n",
    "  * The dataset has a **significantly larger number** of males compared to females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1740457971213,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "koSf_huVYMKY",
    "outputId": "3fcc9c79-8837-4f8f-83ba-113cbc6fec67"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='de_employment_type', data=df_final)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFBjp7RfcRUt"
   },
   "source": [
    "* Full-time Employment Dominates: The **majority of individuals are employed full-time** (29,566), significantly outnumbering part-time employees and business owners.\n",
    "\n",
    "* Distribution of Employment Types:\n",
    "\n",
    "  * Part-time employees (6,621) make up the second-largest group.\n",
    "\n",
    "  * Business owners (4,833) are the smallest group among the specified employment types.\n",
    "\n",
    "  * Minor Unspecified Category: There is a negligible count (2) for an unspecified employment type, which might be an anomaly or error in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1740458055297,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "BcbAOKcwYSzt",
    "outputId": "4eaeaa11-7e15-48f7-f483-ee61b98c705e"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='de_education', data=df_final)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgDlE8WBcoHE"
   },
   "source": [
    "* Senior High School Dominates: The **majority of individuals have completed senior high school** (24,589), **significantly outnumbering** the other education levels.\n",
    "\n",
    "* Distribution of Education Levels:\n",
    "\n",
    "  * The second-largest group is those with an undergraduate degree (8,258).\n",
    "\n",
    "  * Diploma holders (5,758) come next.\n",
    "\n",
    "  * Postgraduate education (1,561) has a relatively smaller count.\n",
    "\n",
    "  * The smallest group is those who have completed only elementary school (856)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1740458058072,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "k_LBbKokYhe0",
    "outputId": "e61afe15-ecb4-49d5-e678-dd853a6ccd96"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='de_marital_status', data=df_final)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qny1UugqdRKQ"
   },
   "source": [
    "* Almost **Equal Distribution** between Single and Married: The number of single individuals (20,154) is **almost equal** to the number of married individuals (20,020).\n",
    "\n",
    "* Small Numbers for Divorced and Widow/Widower:\n",
    "\n",
    "  * There are relatively few individuals who are divorced (500).\n",
    "\n",
    "  * The widow/widower category (348) has the smallest count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1740458208806,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "iCD47McxYwqG",
    "outputId": "44b1d79c-349e-46e9-c3a9-bfc324b37cdc"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='ph_country_code', data=df_final)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fyUJuLeeQvq"
   },
   "source": [
    "* **Dominance of ID** Country Code: The \"id\" country code has an overwhelming count of 40,984, making it the most frequent by far.\n",
    "\n",
    "* Sparse Representation of Other Country Codes:\n",
    "\n",
    "  * The \"us\" and \"sg\" country codes each have a count of 3.\n",
    "\n",
    "  * The \"my\" and \"jp\" country codes each have a count of 2.\n",
    "\n",
    "  * The \"tw,\" \"kh,\" and \"th\" country codes each have a count of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7pXWl4AiOpp"
   },
   "source": [
    "**We can ignore** this feature in modelling due to **very dominant** of a category compared to other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1740458350585,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "aQJjL-qRZLby",
    "outputId": "46c71430-0b70-4dc3-9def-2ab983a71334"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='fb_gender', data=df_final)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CygbVRBsfBWa"
   },
   "source": [
    "* Male Count is Higher: The bar chart shows that the count of gender males in FB (24,013) is higher than the count of gender females in FB (15,496).\n",
    "\n",
    "* Distribution of Gender:\n",
    "\n",
    "  * The distribution shows that there are significantly more males than females in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1740458556760,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "nvfcUVL1Zuxh",
    "outputId": "b815c9d3-9330-4303-b424-eec5b50ddd65"
   },
   "outputs": [],
   "source": [
    "value_counts = df_final['fb_relation'].value_counts()\n",
    "\n",
    "sns.barplot(x=value_counts.values, y=value_counts.index, palette=\"Blues_r\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"fb_relation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUyM9laCfViK"
   },
   "source": [
    "* \"Married\" is the **Most Common Status in FB**: The majority of individuals fall under the \"Married\" category.\n",
    "\n",
    "* \"Single\" and \"In a Relationship\" in FB: These are also **common statuses**, but with fewer individuals compared to \"Married.\"\n",
    "\n",
    "* Less Common Statuses in FB: Relationship statuses like \"It's complicated (Pending)\" and \"In a domestic partnership (Pending)\" have very few individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZK-NUXqgEGC"
   },
   "source": [
    "#### Analysis of Data Similarities between User Self Reported Data and Facebook Profile\n",
    "We will analyze typical users based on the **similarities between the data reported and the data on their Facebook profile**. In this case it will be looked at based on **gender** since it's not common in Indonesia to change gender. We will see flag bad of user that **don't have same data** between self reported data and facebook profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1740551713659,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "Db5PDDv3f29k",
    "outputId": "02be0746-7feb-4ee6-c900-b404bea95171"
   },
   "outputs": [],
   "source": [
    "# Different Gender\n",
    "different_gender = df_final[((df_final['de_gender'] == 1) & (df_final['fb_gender'] == 'female')) | ((df_final['de_gender'] == 2) & (df_final['fb_gender'] == 'male'))]\n",
    "different_gender['flag_bad'].value_counts()\n",
    "\n",
    "ax = sns.countplot(x='flag_bad', data=different_gender)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqRprVT6o0NJ"
   },
   "source": [
    "From the graph we can see, user that have different gender data in user reported data and facebook profile, **17.4% of them is bad user**. It is **higher** than percentage of bad user from all data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgaI75jZuGM4"
   },
   "source": [
    "We create a **new feature which is 'is_same_gender'** with value 0 if the user **has same gender** between the data reported and the data on their Facebook profile and 1 if otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1740551716057,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "AOfxIs5vuEJi",
    "outputId": "2fc03c18-3f5d-4ea0-e776-04f1eebf9fd7"
   },
   "outputs": [],
   "source": [
    "df_final['is_same_gender'] = df_final.index.map(\n",
    "    lambda idx: 1 if idx in different_gender.index and df_final.loc[idx, 'de_gender'] == different_gender.loc[idx, 'de_gender'] else 0\n",
    ")\n",
    "df_final['is_same_gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r42axM3bwM-q"
   },
   "source": [
    "### EDA Numerical Variables\n",
    "\n",
    "We ignore **'date'** columns because based on our **subjective assessment**, these columns have no effect on flag_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1740479324521,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "2wMXh_5BBrEA",
    "outputId": "eb926dd3-6770-4b3e-fe00-fd1c97e814d2"
   },
   "outputs": [],
   "source": [
    "numerical_columns.remove('fb_last_updated_date')\n",
    "numerical_columns.remove('de_date_joined')\n",
    "numerical_columns.remove('index')\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJ4jWMOLxbtF"
   },
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "executionInfo": {
     "elapsed": 3274,
     "status": "ok",
     "timestamp": 1740469061674,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "c8TVcmAowQYc",
    "outputId": "ee1f3d71-cce1-4370-877c-cae375559939"
   },
   "outputs": [],
   "source": [
    "# Set up the figure and axes for multiple subplots\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))  # 2 rows, 5 columns\n",
    "\n",
    "# Flatten axes for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each numerical column\n",
    "for i, col in enumerate(numerical_columns):\n",
    "    sns.histplot(df_final[col], bins=30, ax=axes[i], kde=True)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel('')\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNkdZi1JDHQb"
   },
   "source": [
    "1. de_monthly_salary: The distribution is **highly right-skewed** with a **large concentration of values near zero**, indicating the presence of high outliers.\n",
    "\n",
    "2. de_employment_duration: The distribution shows **periodic peaks** and a **significant spike at 50**, suggesting possible grouping or data collection artifacts.\n",
    "\n",
    "3. ph_total_contacts: **Highly right-skewed with a large concentration of values near zero**. A noticeable **spike at a very low value**.\n",
    "Presence of extreme outliers beyond 15,000.\n",
    "\n",
    "4. de_num_friends:** Also right-skewed**, though not as extreme. A long tail with some high values around 5,000, indicating potential outliers.\n",
    "\n",
    "5. de_age: **The distribution is right-skewed**, meaning most of the data points are concentrated toward the lower age range (around 20-35 years).\n",
    "There are a few higher age values (above 50-60 years) that appear less frequently, which might be outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mP5fuUF_z8Ki"
   },
   "source": [
    "#### Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "executionInfo": {
     "elapsed": 1297,
     "status": "ok",
     "timestamp": 1740469091306,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "y5kvRj1n0axy",
    "outputId": "52594624-9bff-4b0d-e84f-d3295fa5537f"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 6))  # 1 row, 5 columns\n",
    "\n",
    "# Flatten axes for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot boxplots\n",
    "for i, col in enumerate(numerical_columns[:3]):  # First 5 numerical columns\n",
    "    sns.boxplot(y=df_final[col], ax=axes[i])\n",
    "    axes[i].set_title(f\"Boxplot: {col}\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 6))  # Another row for remaining 5 columns\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numerical_columns[3:]):  # Remaining 5 numerical columns\n",
    "    sns.boxplot(y=df_final[col], ax=axes[i])\n",
    "    axes[i].set_title(f\"Boxplot: {col}\")\n",
    "\n",
    "# Adjust layout for better visualization\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjqleuuPEgMj"
   },
   "source": [
    "1. de_monthly_salary: The presence of **many high outliers** suggests a wide range of salary values with a few very high earners.\n",
    "\n",
    "2. de_employment_duration: The data is **more evenly distributed**, with a median duration around 40 and **no significant outliers**.\n",
    "\n",
    "3. ph_total_contacts: The presence of **many high outliers** suggests a wide range of total contacts with a few individuals having significantly higher contact counts.\n",
    "\n",
    "4. de_num_friends: The number of friends shows a **wider spread**, with several **high outliers** indicating individuals with a large number of friends.\n",
    "\n",
    "5. de_age: The age distribution shows **most individuals are between 20 and 35** years old, with some outliers representing older ages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B70YgU4hDGIU"
   },
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1740470007094,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "Mlz1ezxBzqAl",
    "outputId": "f5fc0885-8c5b-4c68-857d-14af668f4320"
   },
   "outputs": [],
   "source": [
    "numeric = df_final[numerical_columns]\n",
    "cor = numeric.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cor, cmap=plt.cm.CMRmap_r,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HPhT69MHTQ9"
   },
   "source": [
    "* Strongest Positive Correlations\n",
    "  * de_age & de_children (0.61)\n",
    "    * Older individuals **tend to have more** children.\n",
    "  * de_age & de_employment_duration (0.38)\n",
    "    * Older individuals **tend to have longer employment durations**.\n",
    "  * de_monthly_salary & de_age (0.27)\n",
    "    * Monthly **salary increases with age**, which is expected as work experience grows.\n",
    "\n",
    "* Strongest Negative Correlations\n",
    "  * de_age & de_num_friends (-0.29)\n",
    "    * Older people **tend to have fewer friends** on the Facebook.\n",
    "  * de_children & de_num_friends (-0.21)\n",
    "    * People with more children **tend to have fewer friends**, possibly due to family commitments.\n",
    "    \n",
    "* Weak Correlations (Close to 0)\n",
    "  * ph_total_contacts has low correlation with other variables.\n",
    "    * This suggests phone contacts may **not be strongly related to salary, age, or social behavior**.\n",
    "  * de_num_friends & ph_total_contacts (0.013)\n",
    "    * Having many total phone contacts **does not strongly predict the number of social media friends**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROxgFlFgHr7b"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ohPrqP_H00b"
   },
   "source": [
    "### Handling Outliers\n",
    "We need to handle outliers for 'de_monthly_salary', 'ph_total_contacts', 'de_num_friends' and 'de_age'. We use Log Transformation and Yeo-Johnson Transformation to handle outliers since these algorithms are effective in handling high skewed distributions and has zero values. Then, we will compared those two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1740551723116,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "d-cs9eMuHveB",
    "outputId": "be88f1c8-dca1-44bb-bb5a-227ac48efc12"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 5))\n",
    "\n",
    "transformer = PowerTransformer(method='yeo-johnson')\n",
    "df_final['yeo-johnson_de_monthly_salary'] = transformer.fit_transform(df_final[['de_monthly_salary']])\n",
    "df_final['log_de_monthly_salary'] =  np.log1p(df_final['de_monthly_salary'])\n",
    "\n",
    "axes[0,0].hist(df_final['yeo-johnson_de_monthly_salary'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,0].set_title('yeo-johnson_de_monthly_salary')\n",
    "axes[0,1].hist(df_final['log_de_monthly_salary'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,1].set_title('log_de_monthly_salary')\n",
    "\n",
    "sns.boxplot(y='yeo-johnson_de_monthly_salary', data=df_final, ax=axes[1,0])\n",
    "sns.boxplot(y='log_de_monthly_salary', data=df_final,ax=axes[1,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIva4l3vA7_E"
   },
   "source": [
    "We need extra outlier handling for column 'de_monthly_salary' because there is one very extreme value. We do this extra outlier handling with Winsorization method because we want to **cap extreme** values while keeping all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1740551727141,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "LK2tw5J9BtpN"
   },
   "outputs": [],
   "source": [
    "lower_yeo = df_final['yeo-johnson_de_monthly_salary'].quantile(0.01)  # 1st percentile\n",
    "upper_yeo = df_final['yeo-johnson_de_monthly_salary'].quantile(0.99)  # 99th percentile\n",
    "df_final['yeo-johnson_de_monthly_salary'] = df_final['yeo-johnson_de_monthly_salary'].clip(lower=lower_yeo, upper=upper_yeo)\n",
    "\n",
    "lower_log = df_final['log_de_monthly_salary'].quantile(0.01)  # 1st percentile\n",
    "upper_log = df_final['log_de_monthly_salary'].quantile(0.99)  # 99th percentile\n",
    "df_final['log_de_monthly_salary'] = df_final['log_de_monthly_salary'].clip(lower=lower_log, upper=upper_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1740551729566,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "6JhSWzqnCR9R",
    "outputId": "74001d52-3b8b-4071-fe89-c2adbb5b369c"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0,0].hist(df_final['yeo-johnson_de_monthly_salary'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,0].set_title('yeo-johnson_de_monthly_salary')\n",
    "axes[0,1].hist(df_final['log_de_monthly_salary'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,1].set_title('log_de_monthly_salary')\n",
    "\n",
    "sns.boxplot(y='yeo-johnson_de_monthly_salary', data=df_final, ax=axes[1,0])\n",
    "sns.boxplot(y='log_de_monthly_salary', data=df_final,ax=axes[1,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1740551114154,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "VhB0CEw-7N-O",
    "outputId": "3f9b141e-9ebe-46da-e7a2-358e68d77de5"
   },
   "outputs": [],
   "source": [
    "joblib.dump(transformer, 'transformer_salary.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qD9WE9VoDXHn"
   },
   "source": [
    "**Almost there is no different** graph between Yeo-Johnson Transformation and Log Transformation. We choose **Yeo-Johnson** because this method usually perform better for Machine Learning task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1740551734070,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "Kjigbki8uX0v",
    "outputId": "53dab1ce-12a7-4a09-fb9e-a7236cef2851"
   },
   "outputs": [],
   "source": [
    "df_final['yeo-johnson_ph_total_contacts'] = transformer.fit_transform(df_final[['ph_total_contacts']])\n",
    "df_final['log_ph_total_contacts'] =  np.log1p(df_final['ph_total_contacts'])\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0,0].hist(df_final['yeo-johnson_ph_total_contacts'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,0].set_title('yeo-johnson_ph_total_contacts')\n",
    "axes[0,1].hist(df_final['log_ph_total_contacts'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,1].set_title('log_ph_total_contacts')\n",
    "\n",
    "sns.boxplot(y='yeo-johnson_ph_total_contacts', data=df_final, ax=axes[1,0])\n",
    "sns.boxplot(y='log_ph_total_contacts', data=df_final,ax=axes[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceB0X4pTE7bZ"
   },
   "source": [
    "1. **Yeo-Johnson Transformation**\n",
    "*   Histogram: Histogram is still highly skewed, meaning the transformation did not fully normalize the data.\n",
    "*   Boxplot: Boxplot shows no extreme outliers, suggesting better outlier suppression.\n",
    "\n",
    "2. **Log Transformation**\n",
    "*   Histogram: The histogram is much more balanced, suggesting better normalization.\n",
    "*   Boxplot: The boxplot shows some compression but retains variability.\n",
    "\n",
    "We choose **Log Transformation** since it better normalizes the data, reducing skewness and although outliers are still visible but less extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1740551742016,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "SZdPUHeuuo5c",
    "outputId": "31baa3f9-d3db-4629-a94f-6f1cace20f9c"
   },
   "outputs": [],
   "source": [
    "df_final['yeo-johnson_de_num_friends'] = transformer.fit_transform(df_final[['de_num_friends']])\n",
    "\n",
    "min_value = df_final['de_num_friends'].min()\n",
    "if min_value < 0:\n",
    "    df_final['de_num_friends'] = df_final['de_num_friends'] - min_value + 1\n",
    "\n",
    "df_final['de_num_friends'] = np.log1p(df_final['de_num_friends'])\n",
    "df_final['log_de_num_friends'] =  np.log1p(df_final['de_num_friends'])\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0,0].hist(df_final['yeo-johnson_de_num_friends'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,0].set_title('yeo-johnson_de_num_friends')\n",
    "axes[0,1].hist(df_final['log_de_num_friends'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,1].set_title('log_de_num_friends')\n",
    "\n",
    "sns.boxplot(y='yeo-johnson_de_num_friends', data=df_final, ax=axes[1,0])\n",
    "sns.boxplot(y='log_de_num_friends', data=df_final,ax=axes[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1740551213873,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "YSrB3D277tcx",
    "outputId": "c3bf9931-c8e7-4201-c2bd-1e0504b0f94b"
   },
   "outputs": [],
   "source": [
    "joblib.dump(transformer, 'transformer_friend.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ve56UinGUvJ"
   },
   "source": [
    "1. Yeo-Johnson Transformation:\n",
    "\n",
    "  * Histogram: The data appears to be roughly normally distributed, centered around 0.\n",
    "\n",
    "  * Box Plot: Shows the spread and outliers of the transformed data. The box plot indicates that there are a few outliers present, as shown by the circles below the lower whisker.\n",
    "\n",
    "2. Log Transformation:\n",
    "\n",
    "  * Histogram: The data is skewed to the right, with a concentration of values around 1.1.\n",
    "\n",
    "  * Box Plot: Shows the spread and outliers of the transformed data. The box plot indicates that there are several outliers present, as shown by the circles below the lower whisker.\n",
    "\n",
    "We choose **Yeo-Johnson** since the Yeo-Johnson transformation appears to **handle outliers better as it produces a more normally distributed dataset** with fewer outliers. This transformation method may provide more reliable results for further statistical analyses and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 1307,
     "status": "ok",
     "timestamp": 1740551750765,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "rwjT7vylupd6",
    "outputId": "81da1ad6-ed9a-4863-9d9c-d9a9dc79b9a7"
   },
   "outputs": [],
   "source": [
    "df_final['yeo-johnson_de_age'] = transformer.fit_transform(df_final[['de_age']])\n",
    "df_final['log_de_age'] =  np.log1p(df_final['de_age'])\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0,0].hist(df_final['yeo-johnson_de_age'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,0].set_title('yeo-johnson_de_age')\n",
    "axes[0,1].hist(df_final['log_de_age'], bins=10, color='blue', edgecolor='black')\n",
    "axes[0,1].set_title('log_de_age')\n",
    "\n",
    "sns.boxplot(y='yeo-johnson_de_age', data=df_final, ax=axes[1,0])\n",
    "sns.boxplot(y='log_de_age', data=df_final,ax=axes[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1740551243626,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "kBqSMAUZ8Bgz",
    "outputId": "ee428c66-345c-404a-dd8c-c0ee9c41558f"
   },
   "outputs": [],
   "source": [
    "joblib.dump(transformer, 'transformer_age.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia_NoykrHFz8"
   },
   "source": [
    "1. Yeo-Johnson Transformation:\n",
    "\n",
    "  * Results in a more symmetric distribution.\n",
    "\n",
    "  * Fewer outliers compared to the logarithmic transformation.\n",
    "\n",
    "2. Logarithmic Transformation:\n",
    "\n",
    "  * Results in a skewed distribution.\n",
    "\n",
    "  * More outliers compared to the Yeo-Johnson transformation.\n",
    "\n",
    "We choose **Yeo-Johnson** since the Yeo-Johnson transformation appears to **handle outliers better as it produces a more normally distributed dataset** with fewer outliers. This transformation method may provide more reliable results for further statistical analyses and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxADF2JoH3Cy"
   },
   "source": [
    "### Handling Missing Values\n",
    "Because the missing values in the 'fb_relation' column are **more than 50%** of the data, we do not use that column. So the columns we will handle missing values juts 'fb_gender' becaues based on our **subjective assessment**, 'ph_call_log_stats' has no effect on flag_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4z32-o1jOwC"
   },
   "source": [
    "We use **mode imputation** to handle missing values for column 'fb_gender' because missing values are random and low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1740551758073,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "mxGvUfd7SqOB",
    "outputId": "cdce7be0-92d1-4372-9c36-5b0c669673a3"
   },
   "outputs": [],
   "source": [
    "df_final['fb_gender'].fillna(df_final['fb_gender'].mode()[0], inplace=True)\n",
    "df_final['fb_gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2mvh7KOIAFD"
   },
   "source": [
    "### Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_coKzp5dkgp4"
   },
   "source": [
    "We will encode columns **'ph_other_device_info' and 'fb_gender'**. For column 'fb_gender' we use same encoding with column 'de_gender'. For column 'ph_other_device_info' we will **extract information** inside that column before do encoding. For standarization, we **lowercase** text in device codename and brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6186,
     "status": "ok",
     "timestamp": 1740551770230,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "5PUKyGHHH5Tv"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert JSON column to dictionary\n",
    "df_final['ph_other_device_info'] = df_final['ph_other_device_info'].apply(json.loads)\n",
    "\n",
    "# Extract keys into new columns\n",
    "df_final_new = pd.concat([df_final, df_final['ph_other_device_info'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 962
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1740551779851,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "KzZTyS6Xn3K4",
    "outputId": "62c8e126-20e1-4cd3-a7c6-0fcbb91f3f3e"
   },
   "outputs": [],
   "source": [
    "df_final_new['device_codename'] = df_final_new['device_codename'].str.lower()\n",
    "df_final_new['brand'] = df_final_new['brand'].str.lower()\n",
    "display(df_final_new['device_codename'].value_counts())\n",
    "display(df_final_new['brand'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLPeuOjAobbn"
   },
   "source": [
    "We will do **Frequency Encoding** for **'device_codename'** and **'brand'** since there are 1041 and 133 categories in the columns and the column also is nominal data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1740551789319,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "kr7vEuwMnU-Y",
    "outputId": "f2105db7-1fcd-4079-9beb-0162bf0f65ac"
   },
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "gender_mapping = {'male': 1, 'female': 2}\n",
    "df_final_new['fb_gender_encoded'] = df_final_new['fb_gender'].map(gender_mapping)\n",
    "\n",
    "# Frequency Encoding\n",
    "device_freq = df_final_new['device_codename'].value_counts(normalize=True)\n",
    "df_final_new['device_codename_encoded'] = df_final_new['device_codename'].map(device_freq)\n",
    "\n",
    "brand_freq = df_final_new['brand'].value_counts(normalize=True)\n",
    "df_final_new['brand_encoded'] = df_final_new['brand'].map(brand_freq)\n",
    "\n",
    "df_final_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNKVsuExH8nD"
   },
   "source": [
    "### Scaling\n",
    "We use the **Robust Scaler** since the dataset contains outliers and has a non-Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1740551794585,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "YT1SSldHH-GZ"
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "columns_to_scale = ['log_ph_total_contacts','yeo-johnson_de_age','yeo-johnson_de_num_friends','de_children','de_employment_duration','yeo-johnson_de_monthly_salary']\n",
    "df_final_new[columns_to_scale] = scaler.fit_transform(df_final_new[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1740551815693,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "LIH134UA-L0Q",
    "outputId": "02808671-97ff-4f83-c3d6-9d3b50531d87"
   },
   "outputs": [],
   "source": [
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1889,
     "status": "ok",
     "timestamp": 1740552562477,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "BdAYQ0FsAnQO"
   },
   "outputs": [],
   "source": [
    "df_final_new.to_csv('dataset_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAkVbyhSsJo3"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIC-swFDsYqf"
   },
   "source": [
    "### Feature Selection (Backward Elimination)\n",
    "\n",
    "We will perform feature selection to identify and retain the most relevant features that contribute significantly to predicting the target variable. This step ensures we reduce noise, enhance model performance, and improve interpretability.\n",
    "\n",
    "In our analysis, we employ the backward elimination method to select the most relevant features for our model. Backward elimination is an iterative process that begins with all potential features and removes the least significant feature in each iteration. This process continues until the optimal set of features is identified, based on the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1740500582731,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "ZLvXNthfsa8G"
   },
   "outputs": [],
   "source": [
    "columns_to_used = ['log_ph_total_contacts','yeo-johnson_de_age','yeo-johnson_de_num_friends','de_children','de_employment_duration',\n",
    "                   'yeo-johnson_de_monthly_salary','flag_bad','de_gender','de_employment_type','de_education','de_marital_status','is_same_gender',\n",
    "                   'fb_gender_encoded','device_codename_encoded','brand_encoded']\n",
    "\n",
    "data_used = df_final_new[columns_to_used]\n",
    "\n",
    "X = data_used.drop(columns=['flag_bad'])\n",
    "y = data_used['flag_bad']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tPX_FfDAjn_"
   },
   "source": [
    "We used ROC-AUC as metric score because its **binary class problems** and dataset has **unequal class distributions** in variable target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1224482,
     "status": "ok",
     "timestamp": 1740502836710,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "zCFXeo21sNWh",
    "outputId": "9b60047c-9aa9-4647-9ed4-53442058456d"
   },
   "outputs": [],
   "source": [
    "tree_model = RandomForestClassifier(n_estimators=300, random_state=42,class_weight='balanced')\n",
    "def backward_elimination(X, y, model, cv=5):\n",
    "    features = list(X.columns)\n",
    "    best_features = []\n",
    "    optimal_scores = 0\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    while len(features) > 1:\n",
    "        model.fit(X[features], y)\n",
    "        # Evaluate model with cross-validation\n",
    "\n",
    "        scores = cross_val_score(model, X[features], y, cv=cv, scoring='roc_auc')\n",
    "        print(f\"Features: {features}\")\n",
    "        print(f\"CV Score: {np.mean(scores):.4f}\")\n",
    "\n",
    "        # Feature importances\n",
    "        importances = model.feature_importances_\n",
    "        least_important = features[np.argmin(importances)]\n",
    "        print(f\"Removing least important feature: {least_important}\\n\")\n",
    "\n",
    "        if scores.mean() > optimal_scores:\n",
    "            optimal_scores = scores.mean()\n",
    "            best_features = features.copy()\n",
    "\n",
    "        # Remove the least important feature\n",
    "        features.remove(least_important)\n",
    "\n",
    "    print(f\"Best selected feature(s): {best_features}\")\n",
    "    return best_features\n",
    "\n",
    "selected_features_be = backward_elimination(X_train, y_train, tree_model)\n",
    "print(\"Selected Features (Backward):\", selected_features_be)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vU69d3dPEvup"
   },
   "source": [
    "Final Selected Feature(s): ['yeo-johnson_de_num_friends']\n",
    "\n",
    "The final iteration of the backward elimination process identifies **number of friends** as the most significant feature contributing to the model's performance. This indicates that the number of friends has a strong influence on the target variable (flag bad).\n",
    "\n",
    "The backward elimination process effectively narrows down the features to those most impactful in predicting **flag bad**. The identified features span various aspects of the user data, including age, number of childre, number of friends, maritas status and device codename.\n",
    "\n",
    "By focusing on these selected features, we can build a more efficient and accurate predictive mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7cINrniF8Yn"
   },
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "We will experiment with Random Forest, XGBoost, LightGBM and SVC since those algorithm robust to overfitting, good for imbalanced and high-dimensional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 694778,
     "status": "ok",
     "timestamp": 1740505649422,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "FJiTxZbiEeM_",
    "outputId": "1c91ce09-5a8e-48a3-9d3f-8ba7b00e7231"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "# Define Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [300, 400],\n",
    "            \"max_depth\": [3, 6],\n",
    "            \"learning_rate\": [0.01, 0.1]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [300,400],\n",
    "            \"max_depth\": [None, 10],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"min_samples_leaf\": [1, 2],\n",
    "\n",
    "        }\n",
    "    },\n",
    "    \"LGBM\": {\n",
    "        \"model\": LGBMClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [300, 400],\n",
    "            \"num_leaves\": [31, 50],\n",
    "            \"max_depth\": [None, 10],\n",
    "            \"learning_rate\": [0.01, 0.1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform Grid Search for each model\n",
    "best_models = {}\n",
    "\n",
    "for name, config in models.items():\n",
    "    print(f\"\\n Running Grid Search for {name}...\\n\")\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=config[\"model\"],\n",
    "        param_grid=config[\"params\"],\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_models[name] = {\n",
    "        \"best_estimator\": grid_search.best_estimator_,\n",
    "        \"best_params\": grid_search.best_params_,\n",
    "        \"best_score\": grid_search.best_score_\n",
    "    }\n",
    "\n",
    "    print(f\"Best ROC-AUC Score for {name}: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\\n\")\n",
    "\n",
    "# Evaluate best models on test data\n",
    "print(\"\\n Evaluating Best Models on Test Set...\\n\")\n",
    "for name, result in best_models.items():\n",
    "    model = result[\"best_estimator\"]\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test, y_probs)\n",
    "    print(f\"{name} Test ROC-AUC Score: {test_auc:.4f}\")\n",
    "\n",
    "# Identify best overall model\n",
    "best_model_name, best_model_info = max(best_models.items(), key=lambda x: x[1][\"best_score\"])\n",
    "best_model = best_model_info[\"best_estimator\"]\n",
    "\n",
    "print(f\"\\n Best Overall Model: {best_model_name} with ROC-AUC: {best_model_info['best_score']:.4f}\")\n",
    "print(f\"Best Parameters: {best_model_info['best_params']}\")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f\"best_model_{best_model_name}.pkl\"\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"\\n Best model saved as: {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfHylnpuUf4K"
   },
   "source": [
    "#### **Insight of Training**\n",
    "\n",
    "1. **Overall Performance**\n",
    "  * The **best model** based on **cross-validation (CV) ROC-AUC** score is **XGBoost** with a CV score of **0.6695**.\n",
    "  * On the **test set**, XGBoost achieved a **ROC-AUC of 0.6816**, which is slightly **higher than** its cross-validation score. This indicates that the model is **generalizing well and is not overfitting**.\n",
    "  * **RandomForest** performed the worst among the three models, with a CV **ROC-AUC of 0.6497** and a test **ROC-AUC of 0.6612**.\n",
    "  * **LGBM** performed **slightly worse** than XGBoost, with a **CV ROC-AUC of 0.6595** and a **test ROC-AUC of 0.6737**\n",
    "\n",
    "2. **XGBoost vs. LGBM vs. Random Forest**\n",
    "\n",
    "  * **XGBoost Insights**\n",
    "\n",
    "    * **Best performing model** with the highest test **ROC-AUC of 0.6816**.\n",
    "    * The chosen hyperparameters (max_depth=3, learning_rate=0.1, n_estimators=400) indicate a **shallow tree with gradual learning**.\n",
    "    * The **CV ROC-AUC (0.6695) is slightly lower than the test ROC-AUC (0.6816)**, which suggests that the model **generalizes well** and is not overfitting.\n",
    "\n",
    "  * **LGBM Insights**\n",
    "\n",
    "    * Close second with **ROC-AUC of 0.6737** on the test set.\n",
    "    * Used a **lower learning rate (0.01)**, which means **slower but more stable learning**.\n",
    "    * A **higher max depth (10)** allows for more complex decision boundaries.\n",
    "    * A good alternative if XGBoost is computationally expensive.\n",
    "\n",
    "  * **Random Forest Insights**\n",
    "\n",
    "    * **Lowest performance**, with **ROC-AUC of 0.6612** on the test set.\n",
    "    * The best hyperparameters include **shallower trees (max_depth=10)** and **more estimators (400)**.\n",
    "    * **Tends to struggle with tabular data when compared** to boosting methods like XGBoost and LGBM.\n",
    "\n",
    "3. **Room for Improvement**\n",
    "  * **Feature Engineering**\n",
    "\n",
    "    * Check for **feature importance** from XGBoost (model.feature_importances_) to see if some features are irrelevant.\n",
    "    * Try **creating new features** (e.g., polynomial features, interactions, domain-specific transformations).\n",
    "\n",
    "  * Handling Class Imbalance (if applicable)\n",
    "\n",
    "    * If your dataset is **imbalanced**, try **SMOTE (Synthetic Minority Over-sampling Technique)** or **class-weight adjustments**.\n",
    "\n",
    "  * Hyperparameter Tuning\n",
    "\n",
    "    * Try **more hyperparameter** for tuning.\n",
    "\n",
    "  * Try Ensemble Learning\n",
    "\n",
    "    * **Combine XGBoost and LGBM** into an ensemble model (e.g., Voting Classifier or Stacking).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp1SooI_QK8H"
   },
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "executionInfo": {
     "elapsed": 2275,
     "status": "ok",
     "timestamp": 1740506784583,
     "user": {
      "displayName": "Putu Eka Surya Aditya",
      "userId": "08696135580964112909"
     },
     "user_tz": -420
    },
    "id": "eP2uqJ66A9vN",
    "outputId": "5c1a79b8-a58a-4bac-e86c-5b5af6658290"
   },
   "outputs": [],
   "source": [
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "feature_df = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_df, palette=\"viridis\")\n",
    "plt.title(\"XGBoost Feature Importance\", fontsize=14)\n",
    "plt.xlabel(\"Importance Score\", fontsize=12)\n",
    "plt.ylabel(\"Feature\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5SlwHjSTPOn"
   },
   "source": [
    "The most influential features (highest importance scores) are:\n",
    "1. de_education: The most important feature, suggesting that **education level plays a major role** to classify bad user.\n",
    "2. de_employment_type: Employment type is also **highly significant**, which makes sense because the model predict behavior of user.\n",
    "3. fb_gender_encoded: **Social media gender classification contributes significantly**, hinting at possible behavioral patterns.\n",
    "4. de_employment_duration: **The length of employment is an important predictor**, indicating that stability in employment matters.\n",
    "\n",
    "These features have the highest impact on the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6K1BIRxUlcs"
   },
   "source": [
    "**Key Takeaways**\n",
    "\n",
    "1. Employment & Education are the biggest predictors: These should be explored further, possibly with interaction effects.\n",
    "2. Gender, Marital Status & Social Factors matter: But they are secondary predictors compared to financial and employment-related features.\n",
    "3. Device and Contact-based features are less relevant: Might be useful in specific contexts but not primary drivers.\n",
    "4. Feature Engineering Opportunities: Further transformation or combination of top features (e.g., \"employment duration x education\") might enhance model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNs2V06jbdqt"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR7c7eaabhuh"
   },
   "source": [
    "1. Data Understanding is an **important part of getting insight** from data so that we can carry out **better data processing** at the next stage\n",
    "2. There is **no perfect method** of handling outliers or handling missing values so we have to experiment it also with some methods\n",
    "3. **XGBoost** is the best model, but the performance is still not very high (ROC-AUC 0.6816). While LGBM is a **close second** and might be worth further tuning.\n",
    "4. **Further improvements** can be made through **feature engineering, handling class imbalance, and advanced hyperparameter tuning**.\n",
    "5. The most important feature is **de_education** suggesting that **education level plays a major role** to classify bad user.\n",
    "6. We also make the **webapp** to test the model. You can access it using the following link: [webapp](https://user-classification-chatbot-financial.streamlit.app/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIPpFR9o9SVrlWaiyF8zxy",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
